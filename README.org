#+STARTUP: overview indent

* Linux TFS development environment
There's a Makefile that will git clone the needed repos.

** Usage Notes
*** Launching a "Host <-> Router <-> Router <-> Host" setup.
You can use the tests to bring up a working iptfs ipsec tunnel. You'll need to
have installed ~qemu~, ~socat~, ~python~ and optional but highly recommended
~tmux~, additionally you'll need to install the python requirements,

#+begin_src bash
  python3 -m venv venv
  source venv/bin/activate
  pip install -r python-requirements.txt
#+end_src

Then run a test adding the `--pause` flag, and it will pause before running the first
test, but after having configured the hosts (h1, h2) and routers (r1, r2).

NOTE: If your `sudo` command forces a restricted PATH (~secure_path~) then the
python virtual environment may not work. In this case `sudo bash` and then
activate the virtual environment as root.

NOTE: SUDO: For best results add the following to your ~/etc/sudoers~ config.
This will allow tmux to continue to work inside the sudo environment.

#+begin_src shell
  Defaults env_keep += "TMUX"
  Defaults env_keep += "TMUX_PANE"
#+end_src

#+begin_src shell
  $ sudo -E pytest -s -v tests/simplenet --pause
  [...]
  == PAUSING: before test 'tests/simplenet/test_simplenet.py::test_net_up' ==
#+end_src

or

#+begin_src shell
  $ sudo -E bash
  # tmux # optional but highly useful
  # source venv/bin/activate
  # pytest -s -v tests/simplenet --pause
  [...]
  == PAUSING: before test 'tests/simplenet/test_simplenet.py::test_net_up' ==
#+end_src


You can now log into the running setup in another terminal. Use ~socat~ to log
into the console of the running qemu'd linux.

#+begin_src shell
  $ sudo socat /dev/stdin,rawer,escape=0x1d,,echo=0,icanon=0 \
      unix-connect:/tmp/unet-test/tests.simplenet.test_simplenet/r1/s/console2
#+end_src

You can use ~mucmd~ to simply enter the namespace of the running node (e.g., to
ping from ~h1~ to ~h2~ over the iptfs tunnel use the following command).

#+begin_src shell
  $ sudo mucmd -d /tmp/unet-test/tests.simplenet.test_simplenet h1 ping 10.0.2.4
  PING 10.0.2.4 (10.0.2.4) 56(84) bytes of data.
  64 bytes from 10.0.2.4: icmp_seq=1 ttl=62 time=1.22 ms
  64 bytes from 10.0.2.4: icmp_seq=2 ttl=62 time=1.40 ms
  64 bytes from 10.0.2.4: icmp_seq=3 ttl=62 time=1.25 ms
  ...
#+end_src

*** Qemu
**** consoles
2 serial consoles are created using unix sockets '/tmp/qemu-sock/console' and
'/tmp/qemu-sock/con2'. These can be accessed in the namespace with the following
command:

~socat /dev/stdin,escape=0x1d,rawer unix-connect:/tmp/qemu-sock/console~

And outside of the namespace with

~socat /dev/stdin,escape=0x1d,rawer unix-connect:<rundir>/<name>/s/console~

Where ~<rundir>~ is usually ~/tmp/unet-root/~, so if the node name is ~r1~:

~sudo socat /dev/stdin,rawer,escape=0x1d,,echo=0,icanon=0 unix-connect:/tmp/unet-root/r1/console~

If your ~socat~ doesn't support ~rawer~ option replace with ~raw,echo=0,icanon=0~.
**** GDB
#+begin_src bash
  $ sudo gdb linux/vmlinux
  (gdb) target remote /tmp/unet-root/r1/s/gdbserver
  ...

  or
  (gdb) target remote /tmp/unet-test/tests.simplenet.test_simplenet/r1/s/gdbserver

  target remote /tmp/unet-test/tests.simplenet.test_simplenet/r1/s/gdbserver
  target remote /tmp/unet-test/tests.verify.test_verify/r1/s/gdbserver
  target remote /tmp/unet-test/tests.errors.test_errors/r1/s/gdbserver
  target remote /tmp/unet-test/tests.utpkt.test_utpkt/r1/s/gdbserver
  target remote /tmp/unet-test/tests.stress.test_stress/r2/s/gdbserver

  target remote /tmp/unet-test/tests.errors.test_errors/r2/s/gdbserver
  target remote /tmp/unet-test/tests.simplenet.test_simplenet/r2/s/gdbserver
#+end_src
** Design Notes
*** From Steffen's Mail
[...] look at:

net/xfrm/*
net/ipv4/xfrm*
net/ipv4/esp4*
net/ipv6/xfrm*
net/ipv6/esp6*

> Anything else you think might be useful too would be much appreciated of course.

I think TFS should be a new encapsulation mode. We currently have
tunnel, transport and beet mode (and some odd ipv6 modes). Adding
a tfs_tunnel mode to add all the TFS special stuff would be the
way to go at a first glance. The modes are implemented in:

net/xfrm/xfrm_output.c
net/xfrm/xfrm_input.c

** Bugs
- xfrmi_rcv_cb is looking up xfrm_state from our newly created skb from decaping
  iptfs, but it has not xfrm_state so we panic
  - Need to associate the xfrm_state with new skbs too.. is there a refcnt for this?
